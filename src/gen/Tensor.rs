// automatically generated by the FlatBuffers compiler, do not modify


// @generated

use core::mem;
use core::cmp::Ordering;

extern crate flatbuffers;
use self::flatbuffers::{EndianScalar, Follow};

#[allow(unused_imports, dead_code)]
pub mod dlpack {

  use core::mem;
  use core::cmp::Ordering;

  extern crate flatbuffers;
  use self::flatbuffers::{EndianScalar, Follow};

pub enum DataTypeOffset {}
#[derive(Copy, Clone, PartialEq)]

pub struct DataType<'a> {
  pub _tab: flatbuffers::Table<'a>,
}

impl<'a> flatbuffers::Follow<'a> for DataType<'a> {
  type Inner = DataType<'a>;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    Self { _tab: flatbuffers::Table::new(buf, loc) }
  }
}

impl<'a> DataType<'a> {
  pub const VT_CODE: flatbuffers::VOffsetT = 4;
  pub const VT_BITS: flatbuffers::VOffsetT = 6;
  pub const VT_LANES: flatbuffers::VOffsetT = 8;

  #[inline]
  pub unsafe fn init_from_table(table: flatbuffers::Table<'a>) -> Self {
    DataType { _tab: table }
  }
  #[allow(unused_mut)]
  pub fn create<'bldr: 'args, 'args: 'mut_bldr, 'mut_bldr>(
    _fbb: &'mut_bldr mut flatbuffers::FlatBufferBuilder<'bldr>,
    args: &'args DataTypeArgs
  ) -> flatbuffers::WIPOffset<DataType<'bldr>> {
    let mut builder = DataTypeBuilder::new(_fbb);
    builder.add_lanes(args.lanes);
    builder.add_bits(args.bits);
    builder.add_code(args.code);
    builder.finish()
  }


  #[inline]
  pub fn code(&self) -> u8 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u8>(DataType::VT_CODE, Some(0)).unwrap()}
  }
  #[inline]
  pub fn bits(&self) -> u8 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u8>(DataType::VT_BITS, Some(0)).unwrap()}
  }
  #[inline]
  pub fn lanes(&self) -> u16 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u16>(DataType::VT_LANES, Some(0)).unwrap()}
  }
}

impl flatbuffers::Verifiable for DataType<'_> {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.visit_table(pos)?
     .visit_field::<u8>("code", Self::VT_CODE, false)?
     .visit_field::<u8>("bits", Self::VT_BITS, false)?
     .visit_field::<u16>("lanes", Self::VT_LANES, false)?
     .finish();
    Ok(())
  }
}
pub struct DataTypeArgs {
    pub code: u8,
    pub bits: u8,
    pub lanes: u16,
}
impl<'a> Default for DataTypeArgs {
  #[inline]
  fn default() -> Self {
    DataTypeArgs {
      code: 0,
      bits: 0,
      lanes: 0,
    }
  }
}

pub struct DataTypeBuilder<'a: 'b, 'b> {
  fbb_: &'b mut flatbuffers::FlatBufferBuilder<'a>,
  start_: flatbuffers::WIPOffset<flatbuffers::TableUnfinishedWIPOffset>,
}
impl<'a: 'b, 'b> DataTypeBuilder<'a, 'b> {
  #[inline]
  pub fn add_code(&mut self, code: u8) {
    self.fbb_.push_slot::<u8>(DataType::VT_CODE, code, 0);
  }
  #[inline]
  pub fn add_bits(&mut self, bits: u8) {
    self.fbb_.push_slot::<u8>(DataType::VT_BITS, bits, 0);
  }
  #[inline]
  pub fn add_lanes(&mut self, lanes: u16) {
    self.fbb_.push_slot::<u16>(DataType::VT_LANES, lanes, 0);
  }
  #[inline]
  pub fn new(_fbb: &'b mut flatbuffers::FlatBufferBuilder<'a>) -> DataTypeBuilder<'a, 'b> {
    let start = _fbb.start_table();
    DataTypeBuilder {
      fbb_: _fbb,
      start_: start,
    }
  }
  #[inline]
  pub fn finish(self) -> flatbuffers::WIPOffset<DataType<'a>> {
    let o = self.fbb_.end_table(self.start_);
    flatbuffers::WIPOffset::new(o.value())
  }
}

impl core::fmt::Debug for DataType<'_> {
  fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
    let mut ds = f.debug_struct("DataType");
      ds.field("code", &self.code());
      ds.field("bits", &self.bits());
      ds.field("lanes", &self.lanes());
      ds.finish()
  }
}
pub enum TensorOffset {}
#[derive(Copy, Clone, PartialEq)]

pub struct Tensor<'a> {
  pub _tab: flatbuffers::Table<'a>,
}

impl<'a> flatbuffers::Follow<'a> for Tensor<'a> {
  type Inner = Tensor<'a>;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    Self { _tab: flatbuffers::Table::new(buf, loc) }
  }
}

impl<'a> Tensor<'a> {
  pub const VT_NDIM: flatbuffers::VOffsetT = 4;
  pub const VT_DTYPE: flatbuffers::VOffsetT = 6;
  pub const VT_SHAPE: flatbuffers::VOffsetT = 8;
  pub const VT_STRIDES: flatbuffers::VOffsetT = 10;
  pub const VT_BYTE_OFFSET: flatbuffers::VOffsetT = 12;

  #[inline]
  pub unsafe fn init_from_table(table: flatbuffers::Table<'a>) -> Self {
    Tensor { _tab: table }
  }
  #[allow(unused_mut)]
  pub fn create<'bldr: 'args, 'args: 'mut_bldr, 'mut_bldr>(
    _fbb: &'mut_bldr mut flatbuffers::FlatBufferBuilder<'bldr>,
    args: &'args TensorArgs<'args>
  ) -> flatbuffers::WIPOffset<Tensor<'bldr>> {
    let mut builder = TensorBuilder::new(_fbb);
    builder.add_byte_offset(args.byte_offset);
    if let Some(x) = args.strides { builder.add_strides(x); }
    if let Some(x) = args.shape { builder.add_shape(x); }
    if let Some(x) = args.dtype { builder.add_dtype(x); }
    builder.add_ndim(args.ndim);
    builder.finish()
  }


  #[inline]
  pub fn ndim(&self) -> i32 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<i32>(Tensor::VT_NDIM, Some(0)).unwrap()}
  }
  #[inline]
  pub fn dtype(&self) -> DataType<'a> {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<flatbuffers::ForwardsUOffset<DataType>>(Tensor::VT_DTYPE, None).unwrap()}
  }
  #[inline]
  pub fn shape(&self) -> flatbuffers::Vector<'a, i64> {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<flatbuffers::ForwardsUOffset<flatbuffers::Vector<'a, i64>>>(Tensor::VT_SHAPE, None).unwrap()}
  }
  #[inline]
  pub fn strides(&self) -> Option<flatbuffers::Vector<'a, i64>> {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<flatbuffers::ForwardsUOffset<flatbuffers::Vector<'a, i64>>>(Tensor::VT_STRIDES, None)}
  }
  #[inline]
  pub fn byte_offset(&self) -> u64 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u64>(Tensor::VT_BYTE_OFFSET, Some(0)).unwrap()}
  }
}

impl flatbuffers::Verifiable for Tensor<'_> {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.visit_table(pos)?
     .visit_field::<i32>("ndim", Self::VT_NDIM, false)?
     .visit_field::<flatbuffers::ForwardsUOffset<DataType>>("dtype", Self::VT_DTYPE, true)?
     .visit_field::<flatbuffers::ForwardsUOffset<flatbuffers::Vector<'_, i64>>>("shape", Self::VT_SHAPE, true)?
     .visit_field::<flatbuffers::ForwardsUOffset<flatbuffers::Vector<'_, i64>>>("strides", Self::VT_STRIDES, false)?
     .visit_field::<u64>("byte_offset", Self::VT_BYTE_OFFSET, false)?
     .finish();
    Ok(())
  }
}
pub struct TensorArgs<'a> {
    pub ndim: i32,
    pub dtype: Option<flatbuffers::WIPOffset<DataType<'a>>>,
    pub shape: Option<flatbuffers::WIPOffset<flatbuffers::Vector<'a, i64>>>,
    pub strides: Option<flatbuffers::WIPOffset<flatbuffers::Vector<'a, i64>>>,
    pub byte_offset: u64,
}
impl<'a> Default for TensorArgs<'a> {
  #[inline]
  fn default() -> Self {
    TensorArgs {
      ndim: 0,
      dtype: None, // required field
      shape: None, // required field
      strides: None,
      byte_offset: 0,
    }
  }
}

pub struct TensorBuilder<'a: 'b, 'b> {
  fbb_: &'b mut flatbuffers::FlatBufferBuilder<'a>,
  start_: flatbuffers::WIPOffset<flatbuffers::TableUnfinishedWIPOffset>,
}
impl<'a: 'b, 'b> TensorBuilder<'a, 'b> {
  #[inline]
  pub fn add_ndim(&mut self, ndim: i32) {
    self.fbb_.push_slot::<i32>(Tensor::VT_NDIM, ndim, 0);
  }
  #[inline]
  pub fn add_dtype(&mut self, dtype: flatbuffers::WIPOffset<DataType<'b >>) {
    self.fbb_.push_slot_always::<flatbuffers::WIPOffset<DataType>>(Tensor::VT_DTYPE, dtype);
  }
  #[inline]
  pub fn add_shape(&mut self, shape: flatbuffers::WIPOffset<flatbuffers::Vector<'b , i64>>) {
    self.fbb_.push_slot_always::<flatbuffers::WIPOffset<_>>(Tensor::VT_SHAPE, shape);
  }
  #[inline]
  pub fn add_strides(&mut self, strides: flatbuffers::WIPOffset<flatbuffers::Vector<'b , i64>>) {
    self.fbb_.push_slot_always::<flatbuffers::WIPOffset<_>>(Tensor::VT_STRIDES, strides);
  }
  #[inline]
  pub fn add_byte_offset(&mut self, byte_offset: u64) {
    self.fbb_.push_slot::<u64>(Tensor::VT_BYTE_OFFSET, byte_offset, 0);
  }
  #[inline]
  pub fn new(_fbb: &'b mut flatbuffers::FlatBufferBuilder<'a>) -> TensorBuilder<'a, 'b> {
    let start = _fbb.start_table();
    TensorBuilder {
      fbb_: _fbb,
      start_: start,
    }
  }
  #[inline]
  pub fn finish(self) -> flatbuffers::WIPOffset<Tensor<'a>> {
    let o = self.fbb_.end_table(self.start_);
    self.fbb_.required(o, Tensor::VT_DTYPE,"dtype");
    self.fbb_.required(o, Tensor::VT_SHAPE,"shape");
    flatbuffers::WIPOffset::new(o.value())
  }
}

impl core::fmt::Debug for Tensor<'_> {
  fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
    let mut ds = f.debug_struct("Tensor");
      ds.field("ndim", &self.ndim());
      ds.field("dtype", &self.dtype());
      ds.field("shape", &self.shape());
      ds.field("strides", &self.strides());
      ds.field("byte_offset", &self.byte_offset());
      ds.finish()
  }
}
#[inline]
/// Verifies that a buffer of bytes contains a `Tensor`
/// and returns it.
/// Note that verification is still experimental and may not
/// catch every error, or be maximally performant. For the
/// previous, unchecked, behavior use
/// `root_as_tensor_unchecked`.
pub fn root_as_tensor(buf: &[u8]) -> Result<Tensor, flatbuffers::InvalidFlatbuffer> {
  flatbuffers::root::<Tensor>(buf)
}
#[inline]
/// Verifies that a buffer of bytes contains a size prefixed
/// `Tensor` and returns it.
/// Note that verification is still experimental and may not
/// catch every error, or be maximally performant. For the
/// previous, unchecked, behavior use
/// `size_prefixed_root_as_tensor_unchecked`.
pub fn size_prefixed_root_as_tensor(buf: &[u8]) -> Result<Tensor, flatbuffers::InvalidFlatbuffer> {
  flatbuffers::size_prefixed_root::<Tensor>(buf)
}
#[inline]
/// Verifies, with the given options, that a buffer of bytes
/// contains a `Tensor` and returns it.
/// Note that verification is still experimental and may not
/// catch every error, or be maximally performant. For the
/// previous, unchecked, behavior use
/// `root_as_tensor_unchecked`.
pub fn root_as_tensor_with_opts<'b, 'o>(
  opts: &'o flatbuffers::VerifierOptions,
  buf: &'b [u8],
) -> Result<Tensor<'b>, flatbuffers::InvalidFlatbuffer> {
  flatbuffers::root_with_opts::<Tensor<'b>>(opts, buf)
}
#[inline]
/// Verifies, with the given verifier options, that a buffer of
/// bytes contains a size prefixed `Tensor` and returns
/// it. Note that verification is still experimental and may not
/// catch every error, or be maximally performant. For the
/// previous, unchecked, behavior use
/// `root_as_tensor_unchecked`.
pub fn size_prefixed_root_as_tensor_with_opts<'b, 'o>(
  opts: &'o flatbuffers::VerifierOptions,
  buf: &'b [u8],
) -> Result<Tensor<'b>, flatbuffers::InvalidFlatbuffer> {
  flatbuffers::size_prefixed_root_with_opts::<Tensor<'b>>(opts, buf)
}
#[inline]
/// Assumes, without verification, that a buffer of bytes contains a Tensor and returns it.
/// # Safety
/// Callers must trust the given bytes do indeed contain a valid `Tensor`.
pub unsafe fn root_as_tensor_unchecked(buf: &[u8]) -> Tensor {
  flatbuffers::root_unchecked::<Tensor>(buf)
}
#[inline]
/// Assumes, without verification, that a buffer of bytes contains a size prefixed Tensor and returns it.
/// # Safety
/// Callers must trust the given bytes do indeed contain a valid size prefixed `Tensor`.
pub unsafe fn size_prefixed_root_as_tensor_unchecked(buf: &[u8]) -> Tensor {
  flatbuffers::size_prefixed_root_unchecked::<Tensor>(buf)
}
#[inline]
pub fn finish_tensor_buffer<'a, 'b>(
    fbb: &'b mut flatbuffers::FlatBufferBuilder<'a>,
    root: flatbuffers::WIPOffset<Tensor<'a>>) {
  fbb.finish(root, None);
}

#[inline]
pub fn finish_size_prefixed_tensor_buffer<'a, 'b>(fbb: &'b mut flatbuffers::FlatBufferBuilder<'a>, root: flatbuffers::WIPOffset<Tensor<'a>>) {
  fbb.finish_size_prefixed(root, None);
}
}  // pub mod dlpack

